{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from SolarFlareNet_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Window = [24]\n",
    "Class = [\"M\"]\n",
    "feature_names = 'TOTUSJH,TOTUSJZ,USFLUX,TOTBSQ,R_VALUE,TOTPOT,SAVNCPP,AREA_ACR,ABSNJZH'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def combine_images(columns, space, images, fname):\n",
    "    rows = len(images) // columns\n",
    "    if len(images) % columns:\n",
    "        rows += 1\n",
    "    width_max = max([Image.open(image).width for image in images])\n",
    "    height_max = max([Image.open(image).height for image in images])\n",
    "    background_width = width_max*columns + (space*columns)-space\n",
    "    background_height = height_max*rows + (space*rows)-space\n",
    "    background = Image.new('RGBA', (background_width, background_height), (255, 255, 255, 255))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for i, image in enumerate(images):\n",
    "        img = Image.open(image)\n",
    "        x_offset = int((width_max-img.width)/2)\n",
    "        y_offset = int((height_max-img.height)/2)\n",
    "        background.paste(img, (x+x_offset, y+y_offset))\n",
    "        x += width_max + space\n",
    "        if (i+1) % columns == 0:\n",
    "            y += height_max + space\n",
    "            x = 0\n",
    "    background.save('%s' %fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to save plots\n",
    "\n",
    "def create_plot_dir(path):\n",
    "    os.makedirs(path,  exist_ok=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Train existing models for SolarFlareNet C,M, and M5 flares for  24, 47, and 72 hours.\n",
    "#You change the values to limit the flare types and number of hours to train.\n",
    "print('Loading the train_model function...')\n",
    "from SolarFlareNet_train import *\n",
    "for time_window in Window:\n",
    "    for flare_class in Class:\n",
    "        train(str(time_window), flare_class)\n",
    "        log('===========================================================\\n\\n',verbose=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "#!pip install lime (to run LIME)\n",
    "#!pip install git+https://github.com/MaximeJumelle/ALEPython.git@dev#egg=alepython (to run ALE)\n",
    "#!pip install alibi[ray] (to run ALE)\n",
    "#!pip install shap (to run SHAP)\n",
    "#!pip install timeshap (to run SHAP)\n",
    "\n",
    "from lime.lime_tabular import RecurrentTabularExplainer\n",
    "from alibi.explainers import KernelShap\n",
    "from alibi.explainers import ALE, plot_ale\n",
    "from alepython import ale_plot\n",
    "#import shap\n",
    "#from shap import DeepExplainer\n",
    "#import timeshap\n",
    "#from timeshap.explainer import local_pruning, local_event, local_feat, local_cell_level\n",
    "#from timeshap.plot import plot_temp_coalition_pruning, plot_event_heatmap, plot_feat_barplot, plot_cell_level\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "#Test existing models for SolarFlareNet C,M, and M5 flares for  24, 47, and 72 hours.\n",
    "#You change the values to limit the flare types and number of hours to test.\n",
    "\n",
    "# You change the tools listed in the interpretable_tools dict for using a specific tool to interpret\n",
    "# LIME key takes a list of instances or a slice which consideres instances upto that range (i.e. example [:1000])\n",
    "# ALE key takes a list containg types of plot we want. [\"1D\", \"2D\"]\n",
    "# SHAP tool is not yet implemented.\n",
    "\n",
    "interpretable_tools = {\"LIM\":[[2], slice(5)], \"ALE\":[\"1D\", \"2D\"], \"SHA\":3}\n",
    "tool_fn = lambda x: print(\"Interpreting using %s method\" %x)\n",
    "limit = 10000\n",
    "top_features = []\n",
    "\n",
    "for time_window in Window:\n",
    "    for flare_class in Class:\n",
    "        model, train_data, test_data = test(str(time_window), flare_class)\n",
    "        X_train, y_train, X_test, y_test = train_data[0][:limit], train_data[1][:limit], test_data[0][:limit], test_data[1][:limit]\n",
    "        #model.summary()\n",
    "        log('===========================================================\\n\\n',verbose=True)\n",
    "        for tool in interpretable_tools:\n",
    "            if tool == \"LIME\":\n",
    "                tool_fn(tool)\n",
    "                model_mask = model.get_model()\n",
    "                explainer = RecurrentTabularExplainer(X_train, training_labels=y_train, feature_names=feature_names,\n",
    "                                                    discretize_continuous=True, verbose=False, feature_selection='none',\n",
    "                                                    class_names=['Negative', 'Positive'], discretizer='decile')\n",
    "                instances = interpretable_tools[tool]\n",
    "                for instance in instances:\n",
    "                    if isinstance(instance, list):\n",
    "                        for i in instance:\n",
    "                            exp = explainer.explain_instance(X_test[i], model_mask.predict, num_features=len(feature_names), num_samples=5000)\n",
    "                            exp.show_in_notebook()\n",
    "                            #exp.as_pyplot_figure()\n",
    "                            #exp.save_to_file(file_path=\"interpret/%s_%d.html\" %(flare_class,time_window))\n",
    "                    elif isinstance(instance, slice):\n",
    "                        feature_rank = {x:[] for x in feature_names}\n",
    "                        for data in X_test[instance]:\n",
    "                            exp = explainer.explain_instance(data, model_mask.predict, num_features=len(feature_names), num_samples=5000)\n",
    "                            exp_map = exp.as_map()\n",
    "                            for k, rank in enumerate(exp_map[1]):\n",
    "                                feature_rank[feature_names[rank[0]]].append(k+1)\n",
    "                        feature_rank = pd.DataFrame(feature_rank)\n",
    "                        final_ranking = feature_rank.mean().sort_values()\n",
    "                        print(final_ranking)\n",
    "                        ranking = final_ranking.to_dict()\n",
    "            elif tool == \"ALE\":\n",
    "                tool_fn(tool)\n",
    "                plot_type = interpretable_tools[tool]\n",
    "                w_dir = 'interpret_models' +os.sep + str(time_window) + os.sep + str(flare_class)\n",
    "                for plt_type in plot_type:\n",
    "                    plt_dir = \"ALE_plots\" + os.sep + str(plt_type) + os.sep + \"%d_%s\" %(time_window,flare_class)\n",
    "                    path_fn = lambda x: plt_dir + os.sep + \"%s.png\" %x\n",
    "                    if plt_type == \"1D\":\n",
    "                        create_plot_dir(plt_dir)\n",
    "                        ale = ALE(model.predict, feature_names=feature_names, target_names=[\"Label\"])\n",
    "                        ale_exp = ale.explain(np.squeeze(X_test), min_bin_points=20)\n",
    "                        ax = plot_ale(ale_exp, n_cols=3, fig_kw={'figwidth':14, 'figheight': 10})\n",
    "                        fig = ax[0][0].get_figure()\n",
    "                        fig.savefig(path_fn(\"%d_%s\" %(time_window,flare_class)))\n",
    "                    elif plt_type == \"2D\":\n",
    "                        create_plot_dir(plt_dir)\n",
    "                        X_train_df = pd.DataFrame(np.squeeze(X_test), columns=feature_names)\n",
    "                        corr = X_train_df.corr(method='kendall')\n",
    "                        sb.heatmap(corr, cmap='YlGnBu', annot=True)\n",
    "                        plt.show()\n",
    "                        plt.rc(\"figure\", figsize=(8,6))\n",
    "                        figures = []\n",
    "                        for i, f1 in enumerate(feature_names):\n",
    "                            for f2 in feature_names[i:]:\n",
    "                                if f1 != f2:\n",
    "                                    ax = ale_plot(model, X_train_df, [f1,f2], bins=10, monte_carlo=True)\n",
    "                                    fig = ax.get_figure()\n",
    "                                    figures += [path_fn(\"%s_%s\" %(f1,f2))]\n",
    "                                    fig.savefig(path_fn(\"%s_%s\" %(f1,f2)))\n",
    "                        combine_images(6, 0, figures, path_fn(\"%d_%s\" %(time_window, flare_class)))\n",
    "            elif tool == \"SHAP\":\n",
    "                tool_fn(tool)\n",
    "                model_mask = model.get_model()\n",
    "                instance = interpretable_tools[tool]\n",
    "\n",
    "                \"\"\"explainer = DeepExplainer(model_mask, X_train)\n",
    "                shap_values = explainer.shap_values(X_test[(instance-1):instance], check_additivity=False)\n",
    "                expected_value = explainer.expected_value\n",
    "                shap.plots.initjs()\n",
    "                display(shap.decision_plot(expected_value[0], shap_values[0][0], feature_names))\n",
    "                display(shap.force_plot(expected_value[0], shap_values[0][0], feature_names=feature_names, \n",
    "                                        matplotlib=True, contribution_threshold=0.005))\n",
    "                \n",
    "                predict_fn = lambda x: model.predict(x)\n",
    "                explainer = KernelShap(predict_fn, link='logit', feature_names=feature_names)\n",
    "                explainer.fit(np.squeeze(X_train[:5000]))\n",
    "                explanation = explainer.explain(np.squeeze(X_test)[(instance-1):instance])\"\"\"\n",
    "                \n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
